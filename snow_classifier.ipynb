{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1c98bae3b34254e00ad38852223e0db4369a8f45fc93c0ffced3852f66cb25c7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Author Information\n",
    "* @Eric Alexander Zair\n",
    "* @Snow Logistic Regression Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Goal\n",
    "\n",
    "### The goal of this notebook is to create a model that can run logistic regression on some weather data (contained in a csv file).\n",
    "\n",
    "### We will use this model to determine if a day is going to snow or not snow."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in our data.\n",
    "weather_df = pd.read_csv('weatherHistory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['Formatted Date', 'Summary', 'Precip Type', 'Temperature (C)',\n       'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)',\n       'Wind Bearing (degrees)', 'Visibility (km)', 'Loud Cover',\n       'Pressure (millibars)', 'Daily Summary'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Let's see what attributes of data we are dealing with.\n",
    "print(weather_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                  Formatted Date        Summary Precip Type  Temperature (C)  \\\n0  2006-04-01 00:00:00.000 +0200  Partly Cloudy        rain         9.472222   \n1  2006-04-01 01:00:00.000 +0200  Partly Cloudy        rain         9.355556   \n2  2006-04-01 02:00:00.000 +0200  Mostly Cloudy        rain         9.377778   \n3  2006-04-01 03:00:00.000 +0200  Partly Cloudy        rain         8.288889   \n4  2006-04-01 04:00:00.000 +0200  Mostly Cloudy        rain         8.755556   \n\n   Apparent Temperature (C)  Humidity  Wind Speed (km/h)  \\\n0                  7.388889      0.89            14.1197   \n1                  7.227778      0.86            14.2646   \n2                  9.377778      0.89             3.9284   \n3                  5.944444      0.83            14.1036   \n4                  6.977778      0.83            11.0446   \n\n   Wind Bearing (degrees)  Visibility (km)  Loud Cover  Pressure (millibars)  \\\n0                   251.0          15.8263         0.0               1015.13   \n1                   259.0          15.8263         0.0               1015.63   \n2                   204.0          14.9569         0.0               1015.94   \n3                   269.0          15.8263         0.0               1016.41   \n4                   259.0          15.8263         0.0               1016.51   \n\n                       Daily Summary  \n0  Partly cloudy throughout the day.  \n1  Partly cloudy throughout the day.  \n2  Partly cloudy throughout the day.  \n3  Partly cloudy throughout the day.  \n4  Partly cloudy throughout the day.  \n"
     ]
    }
   ],
   "source": [
    "# Let's take a better look at the data...\n",
    "print(weather_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove any nan data just in case we run into an issue.\n",
    "weather_df = weather_df.dropna(axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0        rain\n1        rain\n2        rain\n3        rain\n4        rain\n         ... \n96448    rain\n96449    rain\n96450    rain\n96451    rain\n96452    rain\nName: Precip Type, Length: 95936, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# We have a column in our data called \"Precip Type\". This tells what the weather was like that day e.g. rain, snow. This will be our target value later.\n",
    "print(weather_df['Precip Type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of snowy days: 10712\nNumber of all other days: 85224\nPercentage of snowy days: 11.16577718478986\nPercentage of all other days: 88.83422281521014\n"
     ]
    }
   ],
   "source": [
    "# First let's take a look at the data and see how often it snows v.s. how often it does not snow.\n",
    "total_days = weather_df['Precip Type'].count()\n",
    "count_of_snowy_days = len(weather_df[weather_df['Precip Type'] == 'snow'])\n",
    "count_of_all_other_days = weather_df['Precip Type'].count() - count_of_snowy_days\n",
    "\n",
    "print(f\"Number of snowy days: {count_of_snowy_days}\")\n",
    "print(f\"Number of all other days: {count_of_all_other_days}\")\n",
    "\n",
    "print(f\"Percentage of snowy days: {count_of_snowy_days / total_days * 100}\")\n",
    "print(f\"Percentage of all other days: {count_of_all_other_days / total_days * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1562     1\n1563     1\n1564     1\n1565     1\n1566     1\n        ..\n93265    1\n93266    1\n93267    1\n93311    1\n93506    1\nName: Precip Type, Length: 10712, dtype: int64\n0        0\n1        0\n2        0\n3        0\n4        0\n        ..\n96448    0\n96449    0\n96450    0\n96451    0\n96452    0\nName: Precip Type, Length: 85224, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We are going to use \"Precip Type\" to be our target value, but first we need change the layout of the data.\n",
    "# Currently \"Precip Type\" is using Categorical data, but we need to convert the column into integer based data.\n",
    "# We will use 1 to represent snowing, 0 for anything else.\n",
    "y = weather_df['Precip Type'].replace(to_replace=['snow', 'rain'], value=[1, 0])\n",
    "\n",
    "# Just to confirm that replacing these values worked correctly...\n",
    "print(y[y == 1])\n",
    "print(y[y == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                  Formatted Date        Summary Precip Type  Temperature (C)  \\\n0  2006-04-01 00:00:00.000 +0200  Partly Cloudy        rain         9.472222   \n1  2006-04-01 01:00:00.000 +0200  Partly Cloudy        rain         9.355556   \n2  2006-04-01 02:00:00.000 +0200  Mostly Cloudy        rain         9.377778   \n3  2006-04-01 03:00:00.000 +0200  Partly Cloudy        rain         8.288889   \n4  2006-04-01 04:00:00.000 +0200  Mostly Cloudy        rain         8.755556   \n5  2006-04-01 05:00:00.000 +0200  Partly Cloudy        rain         9.222222   \n6  2006-04-01 06:00:00.000 +0200  Partly Cloudy        rain         7.733333   \n7  2006-04-01 07:00:00.000 +0200  Partly Cloudy        rain         8.772222   \n8  2006-04-01 08:00:00.000 +0200  Partly Cloudy        rain        10.822222   \n9  2006-04-01 09:00:00.000 +0200  Partly Cloudy        rain        13.772222   \n\n   Apparent Temperature (C)  Humidity  Wind Speed (km/h)  \\\n0                  7.388889      0.89            14.1197   \n1                  7.227778      0.86            14.2646   \n2                  9.377778      0.89             3.9284   \n3                  5.944444      0.83            14.1036   \n4                  6.977778      0.83            11.0446   \n5                  7.111111      0.85            13.9587   \n6                  5.522222      0.95            12.3648   \n7                  6.527778      0.89            14.1519   \n8                 10.822222      0.82            11.3183   \n9                 13.772222      0.72            12.5258   \n\n   Wind Bearing (degrees)  Visibility (km)  Loud Cover  Pressure (millibars)  \\\n0                   251.0          15.8263         0.0               1015.13   \n1                   259.0          15.8263         0.0               1015.63   \n2                   204.0          14.9569         0.0               1015.94   \n3                   269.0          15.8263         0.0               1016.41   \n4                   259.0          15.8263         0.0               1016.51   \n5                   258.0          14.9569         0.0               1016.66   \n6                   259.0           9.9820         0.0               1016.72   \n7                   260.0           9.9820         0.0               1016.84   \n8                   259.0           9.9820         0.0               1017.37   \n9                   279.0           9.9820         0.0               1017.22   \n\n                       Daily Summary  \n0  Partly cloudy throughout the day.  \n1  Partly cloudy throughout the day.  \n2  Partly cloudy throughout the day.  \n3  Partly cloudy throughout the day.  \n4  Partly cloudy throughout the day.  \n5  Partly cloudy throughout the day.  \n6  Partly cloudy throughout the day.  \n7  Partly cloudy throughout the day.  \n8  Partly cloudy throughout the day.  \n9  Partly cloudy throughout the day.  \n"
     ]
    }
   ],
   "source": [
    "# Let's figure out what features for our X matrix we should be using.\n",
    "print(weather_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = weather_df\n",
    "\n",
    "# Looking at the data:\n",
    "#   We can discrod Daily Summary, as it is basically a repeat of Summary.\n",
    "#   We can drop Formatted Date, as that will not help us predict weather.\n",
    "#   We need to drop Precip Type, it is no longer being used, as that is our target value.\n",
    "#   For now we will drop Summary . We will later add it back and test with it.\n",
    "X = X.drop(columns=['Daily Summary', 'Formatted Date', 'Summary', 'Precip Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Temperature (C)  Apparent Temperature (C)  Humidity  Wind Speed (km/h)  \\\n0         9.472222                  7.388889      0.89            14.1197   \n1         9.355556                  7.227778      0.86            14.2646   \n2         9.377778                  9.377778      0.89             3.9284   \n3         8.288889                  5.944444      0.83            14.1036   \n4         8.755556                  6.977778      0.83            11.0446   \n\n   Wind Bearing (degrees)  Visibility (km)  Loud Cover  Pressure (millibars)  \n0                   251.0          15.8263         0.0               1015.13  \n1                   259.0          15.8263         0.0               1015.63  \n2                   204.0          14.9569         0.0               1015.94  \n3                   269.0          15.8263         0.0               1016.41  \n4                   259.0          15.8263         0.0               1016.51  \n"
     ]
    }
   ],
   "source": [
    "# Our feature matrix...\n",
    "print(X.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of data records in our population data set: 95936\n"
     ]
    }
   ],
   "source": [
    "# How much data records of data do we actually have?\n",
    "print(f\"Number of data records in our population data set: {y.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of test examples: 19188\n",
      "Number of training examples: 76748\n"
     ]
    }
   ],
   "source": [
    "# Before we build our model, let's first split the data into training and testing.\n",
    "# This method should be rather effective, since we have a large amount of data to play with. \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Our testsize will be 20 percent of our population set of data.\n",
    "# We will shuffle the data as well so that it is randomized with a state of 42.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# This should be a reasonable amount of data.\n",
    "print(f\"Number of test examples: {len(y_test)}\")\n",
    "print(f\"Number of training examples: {len(y_train)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Score: 0.9983452337520196\nTesting Score: 0.9985407546383156\n"
     ]
    }
   ],
   "source": [
    "# Alright, let's run our basic Logistic Regression model and see what we get.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# With training data...\n",
    "basic_model = LogisticRegression(random_state=42)\n",
    "basic_model.fit(X_train, y_train)\n",
    "training_score = basic_model.score(X_train, y_train)\n",
    "testing_score = basic_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing is 0.00019552088629604114 percent better.\n"
     ]
    }
   ],
   "source": [
    "# Looking at the data we do NOT appear to be Overfitting or even underfitting at all.\n",
    "# Interestingly enough though, our testing score is slightly higher than our training score.\n",
    "print(f\"Testing is {testing_score - training_score} percent better.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of curiosity, I am going to run 5 fold Cross Validation on the population dataset just to see what we end up getting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would also like to run the same X matrix but with the added \"Summary\" column in it. However, in order to do this, we will have to run one hot encoding and then add those rows to our matrix.\n",
    "#...more on this later..."
   ]
  }
 ]
}